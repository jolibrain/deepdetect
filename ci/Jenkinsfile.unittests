pipeline {
  agent { node { label 'gpu' } }
  stages {
    stage('Init') {
      steps {
        script {
            def common = load("ci/Jenkinsfile.common")
            common.cancelPreviousBuilds()
        }
        sh 'printenv | sort'
      }
    }
    stage('Installing prebuilt cache') {
      when {
       expression { !env.CHANGE_ID || pullRequest.labels.findAll { it == "ci:full-build" }.size() == 0 }
      }
      steps {
        script {
          try {
            copyArtifacts(projectName: 'deepdetect-prebuilt-cache/master')
            sh 'tar -xzf prebuilt-cache-*.tar'
          } catch (err) {
            echo "artefact copy fail, skipping it"
            echo err.getMessage();
          }
        }
      }
    }
    stage('Configure') {
      steps {
        sh '''
export PATH="/usr/lib/ccache/:$PATH"
mkdir -p build
cd build
cmake .. -DBUILD_TESTS=ON -DUSE_CUDNN=ON -DUSE_FAISS=ON -DUSE_SIMSEARCH=ON -DUSE_TSNE=ON -DUSE_XGBOOST=ON -DUSE_TORCH=ON -DUSE_NCNN=ON -DUSE_TENSORRT=ON -DUSE_TENSORRT_OSS=ON -DCUDA_ARCH="-gencode arch=compute_61,code=sm_61"
'''
      }
    }
    stage('Check codestyle') {
      steps {
        sh 'cd build && make clang-format-check'
      }
    }
    stage('Check python client') {
      steps {
        sh 'cd clients/python/ && tox -e pep8,py36,py27'
      }
    }
    stage('Build GPU') {
      steps {
        sh '''
export PATH="/usr/lib/ccache/:$PATH"
cd build
schedtool -B -n 1 -e ionice -n 1 make -j24 pytorch caffe_dd Multicore-TSNE faisslib ncnn xgboost cpp-netlib tensorrt-oss
# TODO(sileht): we should create the prebuilt artefacts here after each successful master branch build
schedtool -B -n 1 -e ionice -n 1 make -j 6
ccache -s
'''
      }
    }
    stage('Tests GPU') {
      steps {
        lock(resource: null, label: "${NODE_NAME}-gpu", variable: 'LOCKED_GPU', quantity: 1) {
          sh '''
          export CUDA_VISIBLE_DEVICES=${LOCKED_GPU##*GPU }
          echo "****************************"
          echo
          python3 -c 'import torch, sys; c=torch.cuda.device_count() ; print(f"CUDA VISIBLE GPU: {c}"); sys.exit(bool(c == 0 ))'
          echo
          echo "****************************"
          cd build && ctest -V -E "http|multigpu"
          '''
          }
      }
    }
/*
    stage('Tests multi-GPU') {
      steps {
        lock(resource: null, label: 'gpu', variable: 'LOCKED_GPU', quantity: 2) {
          sh '''
          export CUDA_VISIBLE_DEVICES=$(echo ${LOCKED_GPU} | sed "s/GPU //g")
          echo "****************************"
          echo
          python3 -c 'import torch, sys; c=torch.cuda.device_count() ; print(f"CUDA VISIBLE GPU: {c}"); sys.exit(bool(c < 2))'
          echo
          echo "****************************"
          cd build && ctest -V -E "http" -R "multigpu"
          '''
          }
      }
    }
*/
  }
  post {
    always {
      cleanWs(cleanWhenAborted: true, cleanWhenFailure: true, cleanWhenNotBuilt: true, cleanWhenSuccess: true, cleanWhenUnstable: true, cleanupMatrixParent: true, deleteDirs: true)
    }
    success {
      catchError {
        rocketSend(channel: 'build', message: 'Build succeed' ,color: 'green' )
      }
    }
    aborted {
      catchError {
        rocketSend(channel: 'build', message: 'Build superseded or aborted')
      }
    }
    unstable {
      catchError {
        rocketSend(channel: 'build', message: 'Build failed', color: 'red')
      }
    }
    failure {
      catchError {
        rocketSend(channel: 'build', message: 'Build failed', color: 'red')
      }
    }
  }
}
